# -*- coding: utf-8 -*-
"""titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AMjVnntLbfw-cfdMnuNO3JI8Uhrxy7EB

### 1. Problem Statement

create a model for predict whether person is surival or not
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as ss

from sklearn.model_selection import train_test_split

from sklearn.pipeline import Pipeline,make_pipeline
from sklearn.preprocessing import PowerTransformer,FunctionTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler,OneHotEncoder,OrdinalEncoder,PowerTransformer,LabelEncoder,FunctionTransformer

from sklearn.compose import ColumnTransformer

from mixed_naive_bayes import MixedNB
from sklearn.metrics import classification_report,confusion_matrix

import pickle

pip install mixed_naive_bayes

"""### 2. Data Collection"""

data = pd.read_csv(r"/content/drive/MyDrive/titanic.csv")
data.head()

"""### 3. EDA before pre-processing"""

data.shape    # this data contains 891 rows and 15 columns

data.info()

data.duplicated().sum()     # data contains 107 dupliate rows so i drop those rows

data.drop_duplicates(keep="first",inplace = True)

data.duplicated().sum()    # data sholud not contains duplicated rows

# based on my problem statement some columns are not at all used for problem statement
# drop unnecessary columns in data set
df = data.drop(["deck","who","adult_male","alive","pclass","embarked","sibsp","parch"],axis=1)

df.info()

df.head()

df.sex.unique()

df["class"].unique()

df.embark_town.unique()    # it will contain missing values called as nan

df.alone.unique()

df.survived.value_counts() # it is imbalanced data

df.columns

# divide my data set into feature variables and class variables
fv = df[['sex', 'age', 'fare', 'class', 'embark_town', 'alone']]
cv = df["survived"]

data["survived"] = data["survived"].map({0:"Un survived",1:"Survived"})

sns.countplot(data.survived)

"""### 4. Pre-processing"""

# convert class column into category and alone column into object type
fv = fv.astype(dtype = {'class':'category','alone':'object'})

fv.info()

# here i can split my data set into x_train and y_train

x_train,x_test,y_train,y_test = train_test_split(fv,cv,test_size=0.2,stratify=cv,random_state=1)

x_train.head()

x_test

y_test

x_train.columns

"""### 5. EDA"""

x_train.corr()

ss.probplot(x_train["fare"],dist = "norm",fit = True,plot = plt)   # x_train["size"] = observed data , norm = theoritical data
plt.show()

ss.probplot(x_train["age"],dist = "norm",fit = True,plot = plt)   # x_train["size"] = observed data , norm = theoritical data
plt.show()

# based on above plots, those numeric values are doesn't follows guassian distribution so I can convert this into gaussian.



"""### 6. Feature Engineering"""

x_train.head(3)

y_train.head(3)

x_test.shape

# split data into numerical,ordinal and nominal seperately.
numerical_data = x_train.select_dtypes(include= ['int64','float64'])
ordinal_data = x_train.select_dtypes(include= ['category'])
nominal_data = x_train.select_dtypes(include=["object"])

numerical_pipe = Pipeline([('imputation_1', SimpleImputer(strategy='mean')),
                           ('StandardScalar', StandardScaler()),
                           ('Power_Transform',PowerTransformer())])

nominal_pipe = Pipeline([('imputation_2', SimpleImputer(strategy='most_frequent')),
                         ('OH_Encoding', OneHotEncoder(sparse_output= False, drop= 'first'))])

ordinal_pipe = Pipeline([('Null_values_imputation_2', SimpleImputer(strategy='most_frequent')),
                         ('Ordinal_Encoding', OrdinalEncoder(categories= [['First', 'Second', 'Third']]))])

prepro_col_trans = ColumnTransformer(transformers= [('Ordinal_Pre-Processing', ordinal_pipe, ordinal_data.columns),
                                                    ('Nominal_Pre-Processing', nominal_pipe, nominal_data.columns),
                                                    ('numerical_Pre-Processing', numerical_pipe, numerical_data.columns)],
                                     remainder="passthrough")

final_pre = Pipeline([('Pre-Processing',prepro_col_trans)])

final_pre.fit_transform(x_train)

pickle.dump(final_pre,open(r"/content/drive/MyDrive/final_pre_titanic.pkl","wb"))

final_x_train = final_pre.fit_transform(x_train)
final_x_test = final_pre.transform(x_test)

final_pre.get_feature_names_out()



"""### 7. Training"""

# I take an algorithm called as MixedNB
mb = MixedNB(categorical_features= [0,1,2,3,4])
model = mb.fit(final_x_train,(y_train))

pickle.dump(model,open(r"/content/drive/MyDrive/titanic_model.pkl","wb"))

"""### 8. Model Evalution"""

print(classification_report(model.predict(final_x_test),y_test))    # my model gives 75% accuracy rate of prediction

confusion_matrix(model.predict(final_x_test),y_test)

"""### 9. Testing"""

res = model.predict(final_x_test[[0]])
if res == 0:
  print("Un servived")
else:
  print("Survived")

"""Finally send a querry point into the model ,then it will gives that the person is Un servived person."""